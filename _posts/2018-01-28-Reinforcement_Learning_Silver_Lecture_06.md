---
layout:     post
title:      Lecture Notes 06
subtitle:   Reinforcement Learning - David Silver's Course
date:       2018-01-28
author:     Sun Yin
header-img: img/rlsilver/fengmian.png
catalog: true
tags:
    - Reinforcement Learning
---
## Lecture 06

**1. Introduction**

**2. Incremental Methods**

**3. Batch Methods**

---

### 1. Introduction

**1.1** What is the general solution for large *MDPs*?

**1.2** What is the requirement for reinforcement learning function approximators?

### 2. Incremental Methods

**2.1** In the gradient descent of least squares, what is $$\Delta w$$?

**2.2** In the case of linear value function approximation, what is $$\Delta w$$?

**2.3** Show that table lookup is just a special case of function approximation.

**2.4** What is the update function of *Monte-Carlo* value function approximation?

**2.5** What is the update function of *TD learning* value function approximation?

**2.6** What is the update function of *$$TD(\lambda)$$* value function approximation(*forward view* and *backward view*)?

**2.7** What is the $$\Delta w$$ of linear action-value function approximation?

**2.8** What is the $$\Delta w$$ of incremental control algorithms for MC, TD(0), forward-view $$TD(\lambda)$$ and backward-view $$TD(\lambda)$$.

**2.9** Show the convergence of prediction algorithms and control algorithms. 

### 3. Batch Methods

**3.1** What is DQN?

**3.2** What is the LSMC, LSTD and $$LSTD(\lambda)$$ algorithm?

**3.3** What is LSTDQ?

**3.4** What is LSPI?



